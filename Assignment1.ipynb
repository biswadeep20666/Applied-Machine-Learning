{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Spam Filter\n",
    "\n",
    "In this assignment we are given a collection of messages some of which are \"spam\"(unwanted messages) and the others are \"ham\".We will try to build a classifier which when trained with sufficient amount of data will be able to distinguish the \"spam\" messages from the \"ham\".For this task we will use three supervised learning procedures:\n",
    "\n",
    "**1.Support Vector Machines**\n",
    "\n",
    "**2.Naive Bayes Classifier**\n",
    "\n",
    "**3.Multilayer Perceptron(Neural Networks)**\n",
    "\n",
    "\n",
    "\n",
    "After fitting these supervised learning models we will evaluate the performance of each model by calculating the accuracy,precision,recall and f1-score on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                sms\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/home/biswadeep/smsspamcollection/SMSSpamCollection', sep='\\t',names=[\"label\", \"sms\"])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='sms', inplace=True) #We drop all the messages that are there twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5169</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh sorry leh... I din c ur msg. Not sad alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                                sms\n",
       "count   5169                                               5169\n",
       "unique     2                                               5169\n",
       "top      ham  Eh sorry leh... I din c ur msg. Not sad alread...\n",
       "freq    4516                                                  1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   sms\n",
       "0   ham  4516\n",
       "1  spam   653"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count().reset_index()#Total Number of Spams and Hams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (5169,)\n",
      "Shape of X_train is (3876,) and shape of y_train is (3876,)\n",
      "Shape of X_test is (1293,) and shape of y_test is (1293,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['sms']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Shape of X is {}\".format(X.shape))\n",
    "print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "train_corpus = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5000\n",
      "Number of omitted words = 2277\n",
      "Shape of X_train_text_features is (3876, 5000)\n"
     ]
    }
   ],
   "source": [
    "#Here we construct the feature vectors for each message using Tf-Idf Vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "print(\"Number of features = {}\".format(len(vectorizer.vocabulary_)))\n",
    "print(\"Number of omitted words = {}\".format(len(vectorizer.stop_words_)))\n",
    "\n",
    "X_train_text_features = vectorizer.transform(list(X_train))\n",
    "print(\"Shape of X_train_text_features is {}\".format(X_train_text_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['sms'].map(lambda x: len(x))\n",
    "\n",
    "X = df[['sms', 'len']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, random_state=42)\n",
    "\n",
    "train_corpus = list(X_train['sms'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "from scipy import sparse\n",
    "def get_features(X):\n",
    "    X_text_features = vectorizer.transform(list(X['sms']))\n",
    "    X_len_features = sparse.csr_matrix(X['len']).T\n",
    "    X_features = sparse.hstack([X_text_features, X_len_features])\n",
    "    return X_features\n",
    "\n",
    "X_train_features = get_features(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine\n",
    "\n",
    "The original SVM algorithm was invented by Vladimir N. Vapnik and Alexey Ya. Chervonenkis in 1963.When we are given data points each belong to one of two classes, and the goal is to decide which class a new data point belong to. In the case of support-vector machines, a data point is viewed as a p-dimensional vector. Now, we want to know whether we can separate the collection of such points with a (p-1)-dimensional hyperplane. This is called a linear classifier. There are many possible hyperplanes that might classify the data sucessfully. One reasonable choice as the best hyperplane is the one that represents the largest separation, or margin, between the two classes. So we choose the hyperplane so that the distance from it to the nearest data point on either side is maximized. If such a hyperplane exists, it is known as the maximum-margin hyperplane and the linear classifier it defines is known as a maximum-margin classifier.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a Support Vector Machine with the data\n",
    "from sklearn import svm\n",
    "model = svm.LinearSVC()\n",
    "\n",
    "model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.963622291022\n",
      "The number of correctly classified samples is 3735\n",
      "The precision score is 0.894976052299\n",
      "The recall score is 0.957960149306\n",
      "The f1 score is 0.923016710026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>3275</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>117</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       3275        24\n",
       "true ham         117       460"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score, precision_score, recall_score\n",
    "\n",
    "y_train_predicted = model.predict(X_train_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_train, \n",
    "                                                                               y_train_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train_predicted, y_train), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9742268  0.93685567 0.92387097 0.94709677 0.94186047]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation within training data: k-fold cross validation\n",
    "        - randomly partition the training data into k parts\n",
    "        - train on k-1 parts and evaluate on the remaining part\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.LinearSVC()\n",
    "cv_scores = cross_val_score(model, X=X_train_features, y=y_train, cv=5, n_jobs=4)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.962877030162\n",
      "The number of correctly classified samples is 1245\n",
      "The precision score is 0.90764288879\n",
      "The recall score is 0.935914106425\n",
      "The f1 score is 0.921075120046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1093</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>31</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       1093        17\n",
       "true ham          31       152"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation on test data: This score is important\n",
    "\"\"\"\n",
    "X_test_features = get_features(X_test)\n",
    "y_test_predicted = model.predict(X_test_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes classifiers are a collection of classification algorithms based on Bayes’ Theorem.Naive Bayes is a technique for constructing models that assign class labels to problem instances which are represented as vectors of feature values where the class labels are drawn from some finite set. There is not a single algorithm for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. \n",
    "\n",
    "For some types of probability models, naive Bayes classifiers can be trained very efficiently in a supervised learning setting. In many practical applications, parameter estimation for naive Bayes models uses the method of maximum likelihood; in other words, one can work with the naive Bayes model without accepting Bayesian probability or using any Bayesian methods. \n",
    "\n",
    "Despite the fact that the far-reaching independence assumptions are often inaccurate, the naive Bayes classifier has several properties that make it surprisingly useful in practice. In particular, the decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one-dimensional distribution. This helps alleviate problems stemming from the curse of dimensionality, such as the need for data sets that scale exponentially with the number of features. While naive Bayes often fails to produce a good estimate for the correct class probabilities,this may not be a requirement for many applications.\n",
    "\n",
    "It is commonly used in problems like :Sex Classification(Male or Female),Document Classification,Spam Filtering etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "X_train_features = X_train_features.toarray()\n",
    "\n",
    "model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.946852425181\n",
      "The number of correctly classified samples is 3670\n",
      "The precision score is 0.850724637681\n",
      "The recall score is 0.969634433962\n",
      "The f1 score is 0.896607503303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>3186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>206</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       3186         0\n",
       "true ham         206       484"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score, precision_score, recall_score\n",
    "\n",
    "y_train_predicted = model.predict(X_train_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_train, \n",
    "                                                                               y_train_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train_predicted, y_train), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91623711 0.9007732  0.8916129  0.91225806 0.92894057]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation within training data: k-fold cross validation\n",
    "        - randomly partition the training data into k parts\n",
    "        - train on k-1 parts and evaluate on the remaining part\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "cv_scores = cross_val_score(clf, X=X_train_features, y=y_train, cv=5, n_jobs=4)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.907192575406\n",
      "The number of correctly classified samples is 1173\n",
      "The precision score is 0.789556900783\n",
      "The recall score is 0.893830676578\n",
      "The f1 score is 0.828119461184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1025</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>99</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       1025        21\n",
       "true ham          99       148"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation on test data: This score is important\n",
    "\"\"\"\n",
    "X_test_features = get_features(X_test)\n",
    "y_test_predicted = model.predict(X_test_features.toarray())\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Perceptron(Neural Nets)\n",
    "\n",
    "An Artificial Neural Network (ANN) is an information processing paradigm that is inspired by the way biological nervous systems, such as the brain, process information. The key element of this paradigm is the novel structure of the information processing system. It is composed of a large number of highly interconnected processing elements (neurones) working in unison to solve specific problems. ANNs, like people, learn by example. An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process. Learning in biological systems involves adjustments to the synaptic connections that exist between the neurones. \n",
    "\n",
    "A multilayer perceptron (MLP) is a class of feedforward artificial neural network. An MLP consists of, at least, three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron.\n",
    "\n",
    "Learning occurs in the perceptron by changing connection weights after each piece of data is processed, based on the amount of error in the output compared to the expected result. This is an example of supervised learning, and is carried out through backpropagation, a generalization of the least mean squares algorithm in the linear perceptron. \n",
    "\n",
    "MLPs are useful in research for their ability to solve problems stochastically, which often allows approximate solutions for extremely complex problems like fitness approximation.\n",
    "\n",
    "MLPs are universal function approximators as showed by Cybenko's theorem so they can be used to create mathematical models by regression analysis. As classification is a particular case of regression when the response variable is categorical, MLPs make good classifier algorithms.\n",
    "\n",
    "MLPs were a popular machine learning solution in the 1980s, finding applications in diverse fields such as speech recognition, image recognition, and machine translation software but thereafter faced strong competition from much simpler support vector machines. Interest in backpropagation networks returned due to the successes of deep learning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-2,hidden_layer_sizes=(5, ), random_state=1)\n",
    "\n",
    "X_train_features = X_train_features\n",
    "\n",
    "model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.99226006192\n",
      "The number of correctly classified samples is 3846\n",
      "The precision score is 0.987381495349\n",
      "The recall score is 0.976979134181\n",
      "The f1 score is 0.982102442736\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>3383</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>9</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       3383        21\n",
       "true ham           9       463"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_train_predicted = model.predict(X_train_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_train, \n",
    "                                                                               y_train_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_train, y_train_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train_predicted, y_train), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99613402 0.98969072 0.97419355 0.98064516 0.98062016]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation within training data: k-fold cross validation\n",
    "        - randomly partition the training data into k parts\n",
    "        - train on k-1 parts and evaluate on the remaining part\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-2,hidden_layer_sizes=(5, ), random_state=1)\n",
    "cv_scores = cross_val_score(clf, X=X_train_features, y=y_train, cv=5, n_jobs=4)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.981438515081\n",
      "The number of correctly classified samples is 1269\n",
      "The precision score is 0.961293221727\n",
      "The recall score is 0.956645223104\n",
      "The f1 score is 0.958952380952\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred spam</th>\n",
       "      <th>pred ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1113</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>11</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred spam  pred ham\n",
       "true spam       1113        13\n",
       "true ham          11       156"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation on test data: This score is important\n",
    "\"\"\"\n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model = MLPClassifier(solver='lbfgs', alpha=1e-2,hidden_layer_sizes=(5, ), random_state=1)\n",
    "\n",
    "\n",
    "model.fit(X_train_features, y_train)\n",
    "X_test_features = get_features(X_test)\n",
    "y_test_predicted = model.predict(X_test_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "print(\"The precision score is {}\".format(precision_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The recall score is {}\".format(recall_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "print(\"The f1 score is {}\".format(f1_score(y_test, y_test_predicted,average = \"macro\")))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
